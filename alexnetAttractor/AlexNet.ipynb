{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat, savemat\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import svm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages(impath, labelpath):\n",
    "    imgs = loadmat(impath)['img_mat'][0]\n",
    "    labels = loadmat(labelpath)\n",
    "    labels = np.squeeze(labels['data']['truth'][0,0])\n",
    "    prepped_imgs = []\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = Image.fromarray(imgs[i]).resize([224,224])\n",
    "        rgb_img = Image.new(\"RGB\", img.size)\n",
    "        rgb_img.paste(img)\n",
    "        prepped_imgs.append(np.array(rgb_img))\n",
    "                                              \n",
    "    prepped_imgs = np.array(prepped_imgs)\n",
    "    prepped_imgs = np.transpose(prepped_imgs,(0,3,1,2))\n",
    "    return prepped_imgs, labels\n",
    "\n",
    "def polarize(tensor):\n",
    "    tensor = tensor.detach().numpy()\n",
    "    tensor[tensor>0]=1\n",
    "    tensor[tensor<0]=-1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 227, 227, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = loadmat('occluded_imgs_sample.mat')['dataset']\n",
    "imgs[0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.children of AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       "  (fc7): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__all__ = ['AlexNet', 'alexnet']\n",
    "\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "\n",
    "# define original alexnet\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        self.fc7 = None\n",
    "\n",
    "    # modify forward to spit out softmax, fc7, and pool 5 for convenience\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        y = self.classifier(x)\n",
    "        z = self.fc7(x)\n",
    "        return {\"softmax\" : y, \"p5\" : x, \"fc7\" : z}\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['alexnet']))\n",
    "    return model\n",
    "\n",
    "# get pretrained alexnet\n",
    "model = alexnet(pretrained=True)\n",
    "\n",
    "# get rid of dropout layers; they make results of forward stochastic.\n",
    "sel = [1,2,4,5,6]\n",
    "model.classifier = nn.Sequential(*[list(model.classifier.children())[i] for i in sel])\n",
    "\n",
    "# define fc7 pass\n",
    "sel = [0,1,2]\n",
    "model.fc7 = nn.Sequential(*[list(model.classifier.children())[i] for i in sel])\n",
    "model.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8159509202453987"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get whole images \n",
    "impath = '../occlusion-classification/data/KLAB325.mat'\n",
    "labelpath = '../occlusion-classification/data/data_occlusion_klab325v2_origimages.mat'\n",
    "\n",
    "X,y = getImages(impath,labelpath)\n",
    "\n",
    "# split data into test and train\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.5, random_state=0)\n",
    "for train_index, test_index in rs.split(X):\n",
    "    X_train = torch.tensor(X[train_index]).float()\n",
    "    y_train = y[train_index]\n",
    "    X_test = torch.tensor(X[test_index]).float()\n",
    "    y_test = y[test_index]\n",
    "\n",
    "# get alexnet features for test and train data\n",
    "X_out_train = model.forward(X_train)\n",
    "X_out_test = model.forward(X_test)\n",
    "fc7_train = polarize(X_out_train['fc7'])\n",
    "fc7_test = polarize(X_out_test['fc7'])\n",
    "\n",
    "# train svm on fc7 representations\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(fc7_train, y_train) \n",
    "\n",
    "# classify fc7 test representations\n",
    "dec = lin_clf.decision_function(fc7_test)\n",
    "y_hat = [hot.argmax()+1 for hot in dec]\n",
    "\n",
    "# quantify accuracy\n",
    "correct = [1 if y_hat[i]==y_test[i] else 0 for i in range(len(y_hat))]\n",
    "sum(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24539877300613497"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get occluded images \n",
    "impath = '../occlusion-classification/data/KLAB325-occluded.mat'\n",
    "labelpath = '../occlusion-classification/data/data_occlusion_klab325v2_origimages.mat'\n",
    "\n",
    "X_occ,y_occ = getImages(impath,labelpath)\n",
    "\n",
    "# use train / test index from unoccluded\n",
    "X_train_occ = torch.tensor(X_occ[train_index]).float()\n",
    "y_train_occ = y_occ[train_index]\n",
    "X_test_occ = torch.tensor(X_occ[test_index]).float()\n",
    "y_test_occ = y_occ[test_index]\n",
    "\n",
    "# get alexnet features for test and train data\n",
    "X_out_train_occ = model.forward(X_train_occ)\n",
    "X_out_test_occ = model.forward(X_test_occ)\n",
    "fc7_train_occ = polarize(X_out_train_occ['fc7'])\n",
    "fc7_test_occ = polarize(X_out_test_occ['fc7'])\n",
    "\n",
    "# use prior svm train on full images\n",
    "# lin_clf = svm.LinearSVC()\n",
    "# lin_clf.fit(fc7_train, y_train) \n",
    "\n",
    "# classify fc7 test representations\n",
    "dec_occ = lin_clf.decision_function(fc7_test_occ)\n",
    "y_hat_occ = [hot.argmax()+1 for hot in dec_occ]\n",
    "\n",
    "# quantify accuracy\n",
    "correct = [1 if y_hat_occ[i]==y_test_occ[i] else 0 for i in range(len(y_hat_occ))]\n",
    "sum(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('../occlusion-classification/data/fc7_features.mat', {\n",
    "    'fc7_train':fc7_train,\n",
    "    'fc7_test':fc7_test,\n",
    "    'fc7_train_occ':fc7_train_occ,\n",
    "    'fc7_test_occ':fc7_test_occ,\n",
    "    'train_labels':y_train,\n",
    "    'test_labels':y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ugh, now run 'featureAttractors.m', which will generate the hopfield network and run fc7_test and tc7_test_occ for 256 timesteps, saving the results to 'fc7_hop_trajs.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'fc7_test_hop_trajs', 'fc7_test_occ_hop_trajs'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc7_hop_trajs = loadmat('fc7_hop_trajs.mat')\n",
    "fc7_hop_trajs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 7, 4096)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc7_trajs = fc7_hop_trajs['fc7_test_hop_trajs']\n",
    "fc7_trajs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc7_trajs[0,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
